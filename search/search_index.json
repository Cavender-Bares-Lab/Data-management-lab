{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data management Welcome This webpage serve as a site for documentation associated with Cavender-Bares Lab . The goal is to have a centralized site where the collaborators can access or create documentation.","title":"Home"},{"location":"#data-management","text":"","title":"Data management"},{"location":"#welcome","text":"This webpage serve as a site for documentation associated with Cavender-Bares Lab . The goal is to have a centralized site where the collaborators can access or create documentation.","title":"Welcome"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/","text":"This site serves as a documentation for the project of Mapping oak-wilt using Sentinel-2. All the data is currently storage at the tier-1 of Minnesota Supercomputing Institute under gruops/cavender/shared/oak-wilt . Many steps of workflow that leads to the structure of the project and data used comes from FORCE . Thus, try to be familiar with it before to reproduce any of the steps. Folder structrue Under gruops/cavender/shared/oak-wilt the folders follow the structure: /oak-wilt - /level1 - /level2 - /level3_monthly-mean - /level3 - /level4 - /log -- /log_sentinel -- /log_landsat - /param - /msi_jobs - /misc -- /csd -- /dem -- /GIS -- /grid -- /mask -- /wvdb - /temp /level1 : contains all the Landsat-8 and Sentinel-2 imagery downloaded. /level2 : contains all the ARD imagery processed through force-level2 /level3_monthly-mean : contains the 5-years average monthly observations of Landsat-8 for the co-registration of Sentinel-2. /level3 : contains all the ARD imagery level3 (e.g., cloud, illumination, shadow masked). /level4 : \u2014 /log : records of the scene processing to create level2 from each sensor. /param : contains all the .prm files to run FORCE for this project. /msi_jobs : contains all the scripts submitted to MSI for processing. /misc/csd : contains the list of scenes to be accessed through Google Cloud Storage. Keep it updated if not scenes available using something similar like force-level1-csd -u ~/misc/csd following force-level1-csd module. /misc/dem : contains the Digital Elevation Model that cover the extend of both Landsat-8 and Sentinel-2 imagery. /misc/GIS : miscellaneous GIS files for the tiles, states, and areas of interest. /misc/mask : contains the mask of area of interest for both states. /misc/grid : GIS files with the datacube tile description. /misc/wvdb : contains the water vapor database. /temp : auxiliary folder for temporal data. Data that falls there can be removed at any time. Sources of Data Digital Elevation Model Copernicus GLO-30 Digital Elevation Model for both states is used, and can be downloaded from OpenTography if required. Water Vapor Database This databases was accessed from Zenodo . If required, it can be updated following FORCE guide . Landsat-8 Landsat-8 scenes were downloaded from Google Cloud Storage using force-level1-csd . The following tiles were used: 026031 025031 024031 023031 022031 030030 029030 028030 027030 026030 025030 024030 023030 022030 021030 030029 029029 028029 027029 026029 025029 024029 023029 022029 021029 031028 030028 029028 028028 027028 026028 025028 024028 023028 022028 031027 030027 029027 028027 027027 026027 025027 024027 023027 031026 030026 029026 028026 027026 026026 025026 024026 031025 030025 029025 028025 027025 Sentinel-2 Sentinel-2 (S2A and S2B) were also downloaded from from Google Cloud Storage using force-level1-csd . The following tiles were used: T14TPP T14TPQ T14TPR T14TPS T14TPT T14TQP T14TQQ T14TQR T14TQS T14TQT T14UPU T14UPV T14UQU T14UQV T15TUJ T15TUK T15TUL T15TUM T15TUN T15TVJ T15TVK T15TVL T15TVM T15TVN T15TWJ T15TWK T15TWL T15TWM T15TWN T15TXH T15TXJ T15TXK T15TXL T15TXM T15TXN T15TYH T15TYJ T15TYK T15TYL T15TYM T15UUP T15UUQ T15UVP T15UWP T15UXP T15UYP T16TCN T16TCP T16TCQ T16TCR T16TCS T16TDN T16TDP T16TDQ T16TDR T16TER Working at Minnesota Supercomputing Institute","title":"Mapping oak-wilt using Sentinel 2"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#folder-structrue","text":"Under gruops/cavender/shared/oak-wilt the folders follow the structure: /oak-wilt - /level1 - /level2 - /level3_monthly-mean - /level3 - /level4 - /log -- /log_sentinel -- /log_landsat - /param - /msi_jobs - /misc -- /csd -- /dem -- /GIS -- /grid -- /mask -- /wvdb - /temp /level1 : contains all the Landsat-8 and Sentinel-2 imagery downloaded. /level2 : contains all the ARD imagery processed through force-level2 /level3_monthly-mean : contains the 5-years average monthly observations of Landsat-8 for the co-registration of Sentinel-2. /level3 : contains all the ARD imagery level3 (e.g., cloud, illumination, shadow masked). /level4 : \u2014 /log : records of the scene processing to create level2 from each sensor. /param : contains all the .prm files to run FORCE for this project. /msi_jobs : contains all the scripts submitted to MSI for processing. /misc/csd : contains the list of scenes to be accessed through Google Cloud Storage. Keep it updated if not scenes available using something similar like force-level1-csd -u ~/misc/csd following force-level1-csd module. /misc/dem : contains the Digital Elevation Model that cover the extend of both Landsat-8 and Sentinel-2 imagery. /misc/GIS : miscellaneous GIS files for the tiles, states, and areas of interest. /misc/mask : contains the mask of area of interest for both states. /misc/grid : GIS files with the datacube tile description. /misc/wvdb : contains the water vapor database. /temp : auxiliary folder for temporal data. Data that falls there can be removed at any time.","title":"Folder structrue"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#sources-of-data","text":"","title":"Sources of Data"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#digital-elevation-model","text":"Copernicus GLO-30 Digital Elevation Model for both states is used, and can be downloaded from OpenTography if required.","title":"Digital Elevation Model"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#water-vapor-database","text":"This databases was accessed from Zenodo . If required, it can be updated following FORCE guide .","title":"Water Vapor Database"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#landsat-8","text":"Landsat-8 scenes were downloaded from Google Cloud Storage using force-level1-csd . The following tiles were used: 026031 025031 024031 023031 022031 030030 029030 028030 027030 026030 025030 024030 023030 022030 021030 030029 029029 028029 027029 026029 025029 024029 023029 022029 021029 031028 030028 029028 028028 027028 026028 025028 024028 023028 022028 031027 030027 029027 028027 027027 026027 025027 024027 023027 031026 030026 029026 028026 027026 026026 025026 024026 031025 030025 029025 028025 027025","title":"Landsat-8"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#sentinel-2","text":"Sentinel-2 (S2A and S2B) were also downloaded from from Google Cloud Storage using force-level1-csd . The following tiles were used: T14TPP T14TPQ T14TPR T14TPS T14TPT T14TQP T14TQQ T14TQR T14TQS T14TQT T14UPU T14UPV T14UQU T14UQV T15TUJ T15TUK T15TUL T15TUM T15TUN T15TVJ T15TVK T15TVL T15TVM T15TVN T15TWJ T15TWK T15TWL T15TWM T15TWN T15TXH T15TXJ T15TXK T15TXL T15TXM T15TXN T15TYH T15TYJ T15TYK T15TYL T15TYM T15UUP T15UUQ T15UVP T15UWP T15UXP T15UYP T16TCN T16TCP T16TCQ T16TCR T16TCS T16TDN T16TDP T16TDQ T16TDR T16TER","title":"Sentinel-2"},{"location":"data-management/nasa-roses/mapping-sentienl2/oak-wilt/#working-at-minnesota-supercomputing-institute","text":"","title":"Working at Minnesota Supercomputing Institute"},{"location":"information-of-interest/information-of-interest/","text":"Lab meeting agenda Lab equipment Lab inventory","title":"Information of interest"},{"location":"information-of-interest/information-of-interest/#lab-meeting-agenda","text":"","title":"Lab meeting agenda"},{"location":"information-of-interest/information-of-interest/#lab-equipment","text":"","title":"Lab equipment"},{"location":"information-of-interest/information-of-interest/#lab-inventory","text":"","title":"Lab inventory"},{"location":"protocols/ankom_fiber_analyzer/","text":"Goal This protocol serves as a guide to use the Ankom Fiber Analyzer. Ankom Protocol for the Hobbie Lab The Ankom Fiber Analyzer utilizes a series of extractions to determine the fiber content of a plant sample. Each of the extractions should be done in the order of NDF (Neutral Detergent Fiber), ADF (Acid Detergent Fiber), then ADL (Acid Determined Lignin). The NDF solution is just soapy water. During NDF, the fraction that is washed off contains soluble cell contents like carbohydrates, lipids, pectin, starch, soluble proteins and non-protein nitrogen. The fraction that is left in the bag contains hemicellulose, proteins bound to the cell walls, cellulose, lignin, and recalcitrant materials. ADF solution is a 1.00 Normal sulfuric acid and detergent solution. During ADF, hemicellulose and bound proteins are washed off. The fraction left behind contains cellulose, lignin, and recalcitrant materials. The ADL solution is ultra nasty 72% sulfuric acid. During ADL, cellulose is washed off leaving only lignin and recalcitrant materials. All calculations can be found in the Template spreadsheet in the Ankom Data folder on the computer in the Hobbie Lab. Supplies All Ankom solutions can be ordered from Ankom: Ankom Technology 140 Turk Hill Park Fairport, NY 14450 phone: 716-425-3940 fax: 716-425-3941 www.ankom.com Updated 2/28/2019 Neutral Detergent solution - catalog # FND20 - 20 L for $95, 20L for $113 Acid Detergent 5x solution - catalog # FAD20 - 1 L (dilutes to 5 L) for $80, 20L for $75, 20L for $93 72% Sulfuric acid - catalog # FSA72 - 1 L for $34 Filter bags - catalog # F57 \u2013 200 for $240, 200 for $252 Steps for sample preparation Grind samples using a 1 mm screen and dry. Label bags with special Ankom marker or permanent Sharpie. Tare Ankom bag and record weight. Weigh out .5 g (\u00b1 0.05 g) of sample and record weight. Include a blank bag in each run (each batch of 24) for a blank bag correction. Seal the bag closed within 0.5 cm from the open edge using the heat sealer. Be sure to seal the blank bag too. Spread sample uniformly inside the filter bag by shaking and lightly flicking the bag to eliminate clumping. A maximum of 24 bags may be place in the bag suspender. All nine trays are used regardless of the number of bags being processed. Place three bags per tray and then stack trays on center post with each level rotated 120 degrees. Each tray will sit in the notches of the tray below it. The weight is placed on top of the empty 9 th tray to keep the bag suspender submerged.","title":"Ankom Fiber Analyzer"},{"location":"protocols/ankom_fiber_analyzer/#goal","text":"This protocol serves as a guide to use the Ankom Fiber Analyzer.","title":"Goal"},{"location":"protocols/ankom_fiber_analyzer/#ankom-protocol-for-the-hobbie-lab","text":"The Ankom Fiber Analyzer utilizes a series of extractions to determine the fiber content of a plant sample. Each of the extractions should be done in the order of NDF (Neutral Detergent Fiber), ADF (Acid Detergent Fiber), then ADL (Acid Determined Lignin). The NDF solution is just soapy water. During NDF, the fraction that is washed off contains soluble cell contents like carbohydrates, lipids, pectin, starch, soluble proteins and non-protein nitrogen. The fraction that is left in the bag contains hemicellulose, proteins bound to the cell walls, cellulose, lignin, and recalcitrant materials. ADF solution is a 1.00 Normal sulfuric acid and detergent solution. During ADF, hemicellulose and bound proteins are washed off. The fraction left behind contains cellulose, lignin, and recalcitrant materials. The ADL solution is ultra nasty 72% sulfuric acid. During ADL, cellulose is washed off leaving only lignin and recalcitrant materials. All calculations can be found in the Template spreadsheet in the Ankom Data folder on the computer in the Hobbie Lab.","title":"Ankom Protocol for the Hobbie Lab"},{"location":"protocols/ankom_fiber_analyzer/#supplies","text":"All Ankom solutions can be ordered from Ankom: Ankom Technology 140 Turk Hill Park Fairport, NY 14450 phone: 716-425-3940 fax: 716-425-3941 www.ankom.com","title":"Supplies"},{"location":"protocols/ankom_fiber_analyzer/#updated-2282019","text":"Neutral Detergent solution - catalog # FND20 - 20 L for $95, 20L for $113 Acid Detergent 5x solution - catalog # FAD20 - 1 L (dilutes to 5 L) for $80, 20L for $75, 20L for $93 72% Sulfuric acid - catalog # FSA72 - 1 L for $34 Filter bags - catalog # F57 \u2013 200 for $240, 200 for $252","title":"Updated 2/28/2019"},{"location":"protocols/ankom_fiber_analyzer/#steps-for-sample-preparation","text":"Grind samples using a 1 mm screen and dry. Label bags with special Ankom marker or permanent Sharpie. Tare Ankom bag and record weight. Weigh out .5 g (\u00b1 0.05 g) of sample and record weight. Include a blank bag in each run (each batch of 24) for a blank bag correction. Seal the bag closed within 0.5 cm from the open edge using the heat sealer. Be sure to seal the blank bag too. Spread sample uniformly inside the filter bag by shaking and lightly flicking the bag to eliminate clumping. A maximum of 24 bags may be place in the bag suspender. All nine trays are used regardless of the number of bags being processed. Place three bags per tray and then stack trays on center post with each level rotated 120 degrees. Each tray will sit in the notches of the tray below it. The weight is placed on top of the empty 9 th tray to keep the bag suspender submerged.","title":"Steps for sample preparation"},{"location":"protocols/hazardous_waste_handling/","text":"Goal This protocol is to guide the proper handling of hazardous waste. Cases Ethanol and bleach wastes can be poured down the sink with large amounts of water. Any plant samples that are not used should be bagged and stored in freezer for further use or autoclaved and disposed of in the garbage.","title":"Hazardous Waste Handling"},{"location":"protocols/hazardous_waste_handling/#goal","text":"This protocol is to guide the proper handling of hazardous waste.","title":"Goal"},{"location":"protocols/hazardous_waste_handling/#cases","text":"Ethanol and bleach wastes can be poured down the sink with large amounts of water. Any plant samples that are not used should be bagged and stored in freezer for further use or autoclaved and disposed of in the garbage.","title":"Cases"},{"location":"protocols/measuring_leaf_area/","text":"Goal The goal of this protocol is to standardize the measurements of leaf area using scanned leaves and Image J. Requirements Scanner Image J software Steps 1. Scanning Leaves Place leaf on front of envelope face down on scanner. The goal is to have leaf and label visible in photo. Make sure a clear ruler is also on the scanner and seen in the image. Enter scanning and camera wizard. Choose color picture and name the file something unique like the date and page number. Save as JPEG image in a folder. Scan photo. Open photo and look to see if it scanned appropriately. Return each leaf to its appropriate envelope. Place leaves in drying oven in back of room 230. 2. Image J Open program Image J. Select File open. Open scanned photo. Click on the line box to select draw line tool. Draw a line on the ruler of a certain length. (8 cm). Select Analyze: Set Scale. Enter 8 under known distance and unit of length cm, check global. Click ok. Select Process: Binary : Make Binary (or Process: Image: Make Binary). The poto will now appear in black and white. Select Analyze: Set measurements. Make sure area, perimeter, and Feret\u2019s diameter are checked. Choose ok. Click on the wand tool. Click on one of the leaves with wand tool. It should highlight the perimeter of the leaf in yellow. If a leaf is touching another leaf or a line it will trace around everything. You will need to use the eraser or draw tool to separate where it is touching. Also if image is split you will need to use draw tool to fill in leaf. Once the leaf is highlighted around the perimeter select Analyze: Measure. A new window will appear with the measurements. Copy these measurements into an excel spreadsheet with appropriate labels and save.","title":"Measuring leaf area"},{"location":"protocols/measuring_leaf_area/#goal","text":"The goal of this protocol is to standardize the measurements of leaf area using scanned leaves and Image J.","title":"Goal"},{"location":"protocols/measuring_leaf_area/#requirements","text":"Scanner Image J software","title":"Requirements"},{"location":"protocols/measuring_leaf_area/#steps","text":"","title":"Steps"},{"location":"protocols/measuring_leaf_area/#1-scanning-leaves","text":"Place leaf on front of envelope face down on scanner. The goal is to have leaf and label visible in photo. Make sure a clear ruler is also on the scanner and seen in the image. Enter scanning and camera wizard. Choose color picture and name the file something unique like the date and page number. Save as JPEG image in a folder. Scan photo. Open photo and look to see if it scanned appropriately. Return each leaf to its appropriate envelope. Place leaves in drying oven in back of room 230.","title":"1. Scanning Leaves"},{"location":"protocols/measuring_leaf_area/#2-image-j","text":"Open program Image J. Select File open. Open scanned photo. Click on the line box to select draw line tool. Draw a line on the ruler of a certain length. (8 cm). Select Analyze: Set Scale. Enter 8 under known distance and unit of length cm, check global. Click ok. Select Process: Binary : Make Binary (or Process: Image: Make Binary). The poto will now appear in black and white. Select Analyze: Set measurements. Make sure area, perimeter, and Feret\u2019s diameter are checked. Choose ok. Click on the wand tool. Click on one of the leaves with wand tool. It should highlight the perimeter of the leaf in yellow. If a leaf is touching another leaf or a line it will trace around everything. You will need to use the eraser or draw tool to separate where it is touching. Also if image is split you will need to use draw tool to fill in leaf. Once the leaf is highlighted around the perimeter select Analyze: Measure. A new window will appear with the measurements. Copy these measurements into an excel spreadsheet with appropriate labels and save.","title":"2. Image J"},{"location":"protocols/surface_sterilization/","text":"Goal This protocol is for the sterilization of surfaces using Ethanol and Bleach. Materials Sterile Water. 70% Ethanol. 70% Bleach. 5 beakers (1 for each of the 5 treatments). Forceps. This should be performed in a BSL1 or BSL2/laminar flow hood to keep the leaves in a sterile environment. Steps First wash: Rinse with sterile water to remove dusts. Second wash: Place the plant sample in 70% ethanol for 1 minute. Third wash: Place the plant sample in Bleach (50% or higher) for 2 minutes. Fourth wash: Place the plant sample in 70% ethanol for 1 minute. Fifth wash: Rinse the plant sample off in sterile water. Leaves are now surface sterilized and can be placed into sterile 50mL tubes, then into -80 storage.","title":"Surface Sterilization"},{"location":"protocols/surface_sterilization/#goal","text":"This protocol is for the sterilization of surfaces using Ethanol and Bleach.","title":"Goal"},{"location":"protocols/surface_sterilization/#materials","text":"Sterile Water. 70% Ethanol. 70% Bleach. 5 beakers (1 for each of the 5 treatments). Forceps. This should be performed in a BSL1 or BSL2/laminar flow hood to keep the leaves in a sterile environment.","title":"Materials"},{"location":"protocols/surface_sterilization/#steps","text":"First wash: Rinse with sterile water to remove dusts. Second wash: Place the plant sample in 70% ethanol for 1 minute. Third wash: Place the plant sample in Bleach (50% or higher) for 2 minutes. Fourth wash: Place the plant sample in 70% ethanol for 1 minute. Fifth wash: Rinse the plant sample off in sterile water. Leaves are now surface sterilized and can be placed into sterile 50mL tubes, then into -80 storage.","title":"Steps"},{"location":"user-guide/test/","text":"test page second line third line","title":"User test"},{"location":"user-guide/user_guide/","text":"User guide Why this webpage? Created, remove, and update documentation is essential for any organization. This webpage was created for this aim using Mkdocs to satisfy the documentation requirements for the lab. This webpage does not not replaceable data storage requirements (e.g., group/cavender, google drive, or local drives). However, it allows users to respond questions like: Where is the data? How the data was collected? What protocol I need to be follow? I am new here, what I need to do? Among many others \u2026 If you need to create, remove, or update documentation please follow the bellows guide, or ask to the lab-technician for help. How to build this webpage? To build this webpage, users must install on their computer: RStudio and R . Rmarkdown and Knitr packages (e.g, install.packages(rmarkdown) ). pip MkDocs (e.g., in terminal pip install mkdocs ) MkDocs material theme (e.i., in terminal pip install mkdocs-material ) git and Github account. Step 1 - Clone or update the webpage repository in your local machine. If you and someone has been working on this webpage or you recent started it is crucial to have the updated version. If you recent started, you can clone the github repository to your local machine using RStudio following: File > New Project ... > Select Version Control > Select Git You will see a \u2018clone git repository\u2019 window, add there the following URL https://github.com/Cavender-Bares-Lab/Data-management-lab.git and chose the project path of your preference. In case you have been working on this webpage using RStudio interface, it is a good practice to check if you have an updated version. For doing so, you only need to click on the Git panel and then click on pull . Remember that you will need git credentials. This first step requires basic git skills, if you are a bit lost take a look at this guide . Step 2 - Let\u2019s get familiar with Mkdocs. In non-technical words, this webpage is composted by two elements: the structure and the documentation. The structure refers to the online appearance of the documentation, and it is controlled by mkdocs.yml file. In this file, under nav: you will see the structure of how the documentation and web sections will be displayed; their sections, tabs, and sub-tabs. The documentation refers to the .md files located in the docs folder. These files contains all the information required that will be displayed in the webpage. It is a good practice to keep these files in folders under docs with names relatives to tabs and sub-tabs, just to keep the webpage in order. Now that we know this elements, let\u2019s take a look at three functions of MkDocs that we will need to use. In RStudio you can run this command using the \u2018Terminal\u2019 (the tab next to \u2018Console\u2019 that we always use). mkdocs serve : this command help us to create local address where we can see the changes in our documentation in real time. This address tend to be http://127.0.0.1:8000/ and it can opened using your browser. mkdocs build : mkdocs gh-deploy : Step 3 - Let\u2019s create a documentation file. Step 4 - Let\u2019s include the documentation in the .yml structure. Step 5 - Let\u2019s build the webpage, we are almost done! Step 6 - Let\u2019s publish the webpage! Step 7 - Double check, we are done! More questions? For more instructions regarding how to build this page you could follow this blog . Likewise, if you have questions regarding Mkdocs take a look at their webpage .","title":"User guide"},{"location":"user-guide/user_guide/#user-guide","text":"","title":"User guide"},{"location":"user-guide/user_guide/#why-this-webpage","text":"Created, remove, and update documentation is essential for any organization. This webpage was created for this aim using Mkdocs to satisfy the documentation requirements for the lab. This webpage does not not replaceable data storage requirements (e.g., group/cavender, google drive, or local drives). However, it allows users to respond questions like: Where is the data? How the data was collected? What protocol I need to be follow? I am new here, what I need to do? Among many others \u2026 If you need to create, remove, or update documentation please follow the bellows guide, or ask to the lab-technician for help.","title":"Why this webpage?"},{"location":"user-guide/user_guide/#how-to-build-this-webpage","text":"To build this webpage, users must install on their computer: RStudio and R . Rmarkdown and Knitr packages (e.g, install.packages(rmarkdown) ). pip MkDocs (e.g., in terminal pip install mkdocs ) MkDocs material theme (e.i., in terminal pip install mkdocs-material ) git and Github account.","title":"How to build this webpage?"},{"location":"user-guide/user_guide/#step-1-clone-or-update-the-webpage-repository-in-your-local-machine","text":"If you and someone has been working on this webpage or you recent started it is crucial to have the updated version. If you recent started, you can clone the github repository to your local machine using RStudio following: File > New Project ... > Select Version Control > Select Git You will see a \u2018clone git repository\u2019 window, add there the following URL https://github.com/Cavender-Bares-Lab/Data-management-lab.git and chose the project path of your preference. In case you have been working on this webpage using RStudio interface, it is a good practice to check if you have an updated version. For doing so, you only need to click on the Git panel and then click on pull . Remember that you will need git credentials. This first step requires basic git skills, if you are a bit lost take a look at this guide .","title":"Step 1 - Clone or update the webpage repository in your local machine."},{"location":"user-guide/user_guide/#step-2-lets-get-familiar-with-mkdocs","text":"In non-technical words, this webpage is composted by two elements: the structure and the documentation. The structure refers to the online appearance of the documentation, and it is controlled by mkdocs.yml file. In this file, under nav: you will see the structure of how the documentation and web sections will be displayed; their sections, tabs, and sub-tabs. The documentation refers to the .md files located in the docs folder. These files contains all the information required that will be displayed in the webpage. It is a good practice to keep these files in folders under docs with names relatives to tabs and sub-tabs, just to keep the webpage in order. Now that we know this elements, let\u2019s take a look at three functions of MkDocs that we will need to use. In RStudio you can run this command using the \u2018Terminal\u2019 (the tab next to \u2018Console\u2019 that we always use). mkdocs serve : this command help us to create local address where we can see the changes in our documentation in real time. This address tend to be http://127.0.0.1:8000/ and it can opened using your browser. mkdocs build : mkdocs gh-deploy :","title":"Step 2 - Let\u2019s get familiar with Mkdocs."},{"location":"user-guide/user_guide/#step-3-lets-create-a-documentation-file","text":"","title":"Step 3 - Let\u2019s create a documentation file."},{"location":"user-guide/user_guide/#step-4-lets-include-the-documentation-in-the-yml-structure","text":"","title":"Step 4 - Let\u2019s include the documentation in the .yml structure."},{"location":"user-guide/user_guide/#step-5-lets-build-the-webpage-we-are-almost-done","text":"","title":"Step 5 - Let\u2019s build the webpage, we are almost done!"},{"location":"user-guide/user_guide/#step-6-lets-publish-the-webpage","text":"","title":"Step 6 - Let\u2019s publish the webpage!"},{"location":"user-guide/user_guide/#step-7-double-check-we-are-done","text":"","title":"Step 7 - Double check, we are done!"},{"location":"user-guide/user_guide/#more-questions","text":"For more instructions regarding how to build this page you could follow this blog . Likewise, if you have questions regarding Mkdocs take a look at their webpage .","title":"More questions?"}]}